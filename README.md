# interview
面试知识准备、输出、笔记总结
## 推荐算法

1）冷启动 

2）特征工程

3）近邻算法  jcard，余弦相似度，皮尔森相关系数，slopeone

3.1)开源项目

4）模型融合 gbdt+lr，fm,deepfm,deep&wide

5）框架

5）开源项目

召回，排序


0-》1

1）冷启动 内容推荐

2）特征工程 大数据处理 架构

3）近邻算法

4）模型融合

5）mab

6）深度学习 

7）攻防问题

8）近期算法论文

改错pycorrect 报告预料
调阀值，召回率 95%

文本挖掘，挖掘黄赌毒用户
fasttext文本挖掘

项目背景

挖掘用户兴趣偏好，打标签，为用户推荐内容

提问：攻防问题处理

gbdt 拿特征

lr 算权重和点击率

## 不平衡数据处理
    对于不平衡的数据集，例如用户的购买行为，肯定是极其不平衡的，这对XGBoost的训练有很大的影响，XGBoost有两种自带的方法来解决：
    
    第一种，如果你在意AUC，采用AUC来评估模型的性能，那你可以通过设置scale_pos_weight来平衡正样本和负样本的权重。例如，当正负样本比例为1:10时，scale_pos_weight可以取10；
    
    第二种，如果你在意概率(预测得分的合理性)，你不能重新平衡数据集(会破坏数据的真实分布)，应该设置max_delta_step为一个有限数字来帮助收敛（基模型为LR时有效）。




